{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":918834,"status":"ok","timestamp":1761894442635,"user":{"displayName":"Anshav Desai","userId":"12679447231453701304"},"user_tz":-330},"id":"tmL0ts9TqQ0n","outputId":"f8d32e11-c567-4035-ff28-5c2009dd7319"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","PROJECT_ROOT: /content/drive/MyDrive/aerial_project\n","CLASSIFICATION_DIR exists: True\n","DETECTION_DIR exists: True\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"efficientnet_b0\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"efficientnet_b0\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ rescaling_2 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │         \u001b[38;5;34m5,120\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m514\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ rescaling_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,383,141\u001b[0m (16.72 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,383,141</span> (16.72 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,171,358\u001b[0m (15.91 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,171,358</span> (15.91 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m211,783\u001b[0m (827.28 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,783</span> (827.28 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Found 2662 files belonging to 2 classes.\n","Class names (saved): ['bird', 'drone']\n","Found 442 files belonging to 2 classes.\n","Found 215 files belonging to 2 classes.\n","Classes: ['bird', 'drone']\n","Class Weights: {0: np.float64(0.9413012729844413), 1: np.float64(1.0665064102564104)}\n","Epoch 1/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.5832 - loss: 1.0378"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.5835 - loss: 1.0369 - val_accuracy: 0.4910 - val_loss: 0.6993 - learning_rate: 1.0000e-04\n","Epoch 2/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 167ms/step - accuracy: 0.6533 - loss: 0.7964 - val_accuracy: 0.4706 - val_loss: 0.7088 - learning_rate: 1.0000e-04\n","Epoch 3/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.6688 - loss: 0.7929 - val_accuracy: 0.4977 - val_loss: 0.8590 - learning_rate: 1.0000e-04\n","Epoch 4/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.6869 - loss: 0.7229 - val_accuracy: 0.5973 - val_loss: 0.7230 - learning_rate: 1.0000e-04\n","Epoch 5/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7168 - loss: 0.6143"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 194ms/step - accuracy: 0.7166 - loss: 0.6146 - val_accuracy: 0.7760 - val_loss: 0.4606 - learning_rate: 5.0000e-05\n","Epoch 6/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7141 - loss: 0.6203"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 181ms/step - accuracy: 0.7143 - loss: 0.6199 - val_accuracy: 0.7692 - val_loss: 0.4558 - learning_rate: 5.0000e-05\n","Epoch 7/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 165ms/step - accuracy: 0.7393 - loss: 0.5424 - val_accuracy: 0.6968 - val_loss: 0.5479 - learning_rate: 5.0000e-05\n","Epoch 8/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - accuracy: 0.7489 - loss: 0.5173 - val_accuracy: 0.6946 - val_loss: 0.5542 - learning_rate: 5.0000e-05\n","Epoch 9/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7392 - loss: 0.5330 - val_accuracy: 0.7172 - val_loss: 0.4865 - learning_rate: 5.0000e-05\n","Epoch 10/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 165ms/step - accuracy: 0.7592 - loss: 0.4996 - val_accuracy: 0.7308 - val_loss: 0.5024 - learning_rate: 2.5000e-05\n","Epoch 11/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7423 - loss: 0.5255 - val_accuracy: 0.7059 - val_loss: 0.5674 - learning_rate: 2.5000e-05\n","Epoch 12/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7283 - loss: 0.5242"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 195ms/step - accuracy: 0.7284 - loss: 0.5243 - val_accuracy: 0.7964 - val_loss: 0.4425 - learning_rate: 2.5000e-05\n","Epoch 13/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 166ms/step - accuracy: 0.7508 - loss: 0.4924 - val_accuracy: 0.7715 - val_loss: 0.4846 - learning_rate: 2.5000e-05\n","Epoch 14/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7553 - loss: 0.4840 - val_accuracy: 0.6742 - val_loss: 0.6473 - learning_rate: 2.5000e-05\n","Epoch 15/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7663 - loss: 0.4670 - val_accuracy: 0.7851 - val_loss: 0.4926 - learning_rate: 2.5000e-05\n","Epoch 16/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7531 - loss: 0.5077 - val_accuracy: 0.7624 - val_loss: 0.5635 - learning_rate: 1.2500e-05\n","Epoch 17/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - accuracy: 0.7744 - loss: 0.4501 - val_accuracy: 0.7647 - val_loss: 0.5064 - learning_rate: 1.2500e-05\n","Epoch 18/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7654 - loss: 0.5075 - val_accuracy: 0.7919 - val_loss: 0.4882 - learning_rate: 1.2500e-05\n","Epoch 1/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 200ms/step - accuracy: 0.7526 - loss: 0.5064 - val_accuracy: 0.7602 - val_loss: 0.4730 - learning_rate: 1.0000e-05\n","Epoch 2/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 165ms/step - accuracy: 0.7388 - loss: 0.5077 - val_accuracy: 0.7783 - val_loss: 0.4730 - learning_rate: 1.0000e-05\n","Epoch 3/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - accuracy: 0.7359 - loss: 0.5243 - val_accuracy: 0.6855 - val_loss: 0.6346 - learning_rate: 1.0000e-05\n","Epoch 4/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7639 - loss: 0.5100 - val_accuracy: 0.6855 - val_loss: 0.6484 - learning_rate: 1.0000e-05\n","Epoch 5/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7714 - loss: 0.4582 - val_accuracy: 0.7398 - val_loss: 0.5255 - learning_rate: 5.0000e-06\n","Epoch 6/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.7703 - loss: 0.4561 - val_accuracy: 0.7466 - val_loss: 0.5228 - learning_rate: 5.0000e-06\n","Epoch 7/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.7641 - loss: 0.5170 - val_accuracy: 0.7489 - val_loss: 0.5126 - learning_rate: 5.0000e-06\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["#Colab: 04_train_transfer.ipynb\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.metrics import Precision, Recall\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","import pickle\n","PROJECT_ROOT='/content/drive/MyDrive/aerial_project'\n","CLASSIFICATION_DIR=os.path.join(PROJECT_ROOT, 'classification_dataset')\n","DETECTION_DIR=os.path.join(PROJECT_ROOT, 'object_detection_Dataset')\n","DATA_DIR=os.path.join(PROJECT_ROOT, 'data')\n","SAVED_MODELS=os.path.join(PROJECT_ROOT, 'saved_models')\n","RESULTS_DIR=os.path.join(PROJECT_ROOT, 'results')\n","#create important folders if they don't exist\n","os.makedirs(SAVED_MODELS, exist_ok=True)\n","os.makedirs(RESULTS_DIR, exist_ok=True)\n","print('PROJECT_ROOT:', PROJECT_ROOT)\n","print('CLASSIFICATION_DIR exists:', os.path.exists(CLASSIFICATION_DIR))\n","print('DETECTION_DIR exists:', os.path.exists(DETECTION_DIR))\n","\n","#Data augmentation setup (copied from nb. 02)\n","data_augmentation=tf.keras.Sequential([\n","    layers.RandomFlip('horizontal'),\n","    layers.RandomRotation(0.12),\n","    layers.RandomZoom(0.12),\n","    layers.RandomTranslation(0.08, 0.08),\n","], name='data_augmentation')\n","\n","def build_efficientnet(input_shape=(224,224,3), num_classes=2, freeze_until=100):\n","  base=EfficientNetB0(include_top=False, input_shape=input_shape, weights='imagenet')\n","  base.trainable=True\n","  for layer in base.layers[:freeze_until]:\n","    layer.trainable=False\n","\n","  inputs=layers.Input(shape=input_shape)\n","  x=layers.Rescaling(1./255)(inputs)\n","  x=data_augmentation(x)\n","  x=base(x, training=False)\n","  x=layers.GlobalAveragePooling2D()(x)\n","  x=layers.BatchNormalization()(x)\n","  x=layers.Dropout(0.4)(x)\n","  x=layers.Dense(256, activation='relu')(x)\n","  x=layers.Dropout(0.3)(x)\n","  outputs=layers.Dense(num_classes, activation='softmax')(x)\n","  return models.Model(inputs, outputs, name='efficientnet_b0')\n","\n","model=build_efficientnet()\n","model.summary()\n","model.compile(\n","optimizer=tf.keras.optimizers.Adam(1e-4),\n","loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","metrics=['accuracy'])\n","\n","callbacks=[\n","tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n","tf.keras.callbacks.ModelCheckpoint(os.path.join(SAVED_MODELS,'best_efficientnet.h5'), save_best_only=True, monitor='val_loss'),\n","tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)]\n","\n","#Dataset Loading and Class Weight Setup (copied from nb. 03)\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from sklearn.utils import class_weight\n","import numpy as np\n","\n","IMG_SIZE=(224, 224)\n","BATCH_SIZE=32\n","#train, val, test datasets\n","train_ds=tf.keras.utils.image_dataset_from_directory(\n","    os.path.join(CLASSIFICATION_DIR, 'train'),\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE)\n","\n","#saving the class names(so evaluation and/or streamlit use the same mapping)\n","import json\n","class_names=train_ds.class_names\n","print(\"Class names (saved):\", class_names)\n","with open(os.path.join(SAVED_MODELS, 'class_names.json'), 'w') as f:\n","    json.dump(class_names, f)\n","\n","val_ds=tf.keras.utils.image_dataset_from_directory(\n","    os.path.join(CLASSIFICATION_DIR, 'valid'),\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE)\n","\n","test_ds=tf.keras.utils.image_dataset_from_directory(\n","    os.path.join(CLASSIFICATION_DIR, 'test'),\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE)\n","\n","#class names\n","class_names=train_ds.class_names\n","print(\"Classes:\", class_names)\n","\n","#computing class weights (to handle imbalance)\n","labels=np.concatenate([y for x, y in train_ds], axis=0)\n","class_weights_vals=class_weight.compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(labels),\n","    y=labels\n",")\n","class_weights=dict(enumerate(class_weights_vals))\n","print(\"Class Weights:\", class_weights)\n","\n","# Prefetch for performance\n","AUTOTUNE=tf.data.AUTOTUNE\n","train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds=val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","test_ds=test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","history=model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=callbacks, class_weight=class_weights)\n","#optional fine-tuning: unfreezing the last N layers and train with lower lr\n","fine_tune_at=len(model.layers)-50\n","for layer in model.layers[fine_tune_at:]:\n","  layer.trainable=True\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n","loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","metrics=['accuracy'])\n","history_finetune=model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=callbacks, class_weight=class_weights)\n","\n","#saving history and model\n","import pickle\n","with open(os.path.join(SAVED_MODELS,'history_efficientnet.pkl'),'wb') as f:\n","  pickle.dump({'initial': history.history, 'finetune': history_finetune.history}, f)\n","model.save(os.path.join(SAVED_MODELS,'best_efficientnet_full.h5'))"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50241,"status":"ok","timestamp":1761894492920,"user":{"displayName":"Anshav Desai","userId":"12679447231453701304"},"user_tz":-330},"id":"VIy8e_buUIRg","outputId":"76fe4c24-cd29-4df0-b139-cbad4b4cdd8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 470ms/step\n","              precision    recall  f1-score   support\n","\n","        bird       0.91      0.60      0.73       121\n","       drone       0.64      0.93      0.76        94\n","\n","    accuracy                           0.74       215\n","   macro avg       0.78      0.76      0.74       215\n","weighted avg       0.80      0.74      0.74       215\n","\n","Confusion Matrix:\n"," [[73 48]\n"," [ 7 87]]\n"]}],"source":["#Manual evaluation metrics (after training)\n","from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","#Get predictions\n","y_true=np.concatenate([y for x, y in test_ds], axis=0)\n","y_pred_probs=model.predict(test_ds)\n","y_pred=np.argmax(y_pred_probs, axis=1)\n","#Classification report\n","print(classification_report(y_true, y_pred, target_names=class_names))\n","#Confusion matrix\n","cm=confusion_matrix(y_true, y_pred)\n","print(\"Confusion Matrix:\\n\", cm)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOWa3rDiR9RWIGXDwJ3JwZ0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}