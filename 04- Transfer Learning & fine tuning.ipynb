{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":869646,"status":"ok","timestamp":1761331409223,"user":{"displayName":"Anshav Desai","userId":"12679447231453701304"},"user_tz":-330},"id":"tmL0ts9TqQ0n","outputId":"be97f35c-b315-483e-cc94-3f289968c500"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","PROJECT_ROOT: /content/drive/MyDrive/aerial_project\n","CLASSIFICATION_DIR exists: True\n","DETECTION_DIR exists: True\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"efficientnet_b0\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"efficientnet_b0\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ rescaling_2 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │         \u001b[38;5;34m5,120\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m514\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ rescaling_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,383,141\u001b[0m (16.72 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,383,141</span> (16.72 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,171,358\u001b[0m (15.91 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,171,358</span> (15.91 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m211,783\u001b[0m (827.28 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,783</span> (827.28 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Found 2662 files belonging to 2 classes.\n","Found 442 files belonging to 2 classes.\n","Found 215 files belonging to 2 classes.\n","Classes: ['bird', 'drone']\n","Class Weights: {0: np.float64(0.9413012729844413), 1: np.float64(1.0665064102564104)}\n","Epoch 1/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.6132 - loss: 1.0337"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.6134 - loss: 1.0328 - val_accuracy: 0.4910 - val_loss: 0.6988 - learning_rate: 1.0000e-04\n","Epoch 2/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.6689 - loss: 0.7779 - val_accuracy: 0.4910 - val_loss: 0.7572 - learning_rate: 1.0000e-04\n","Epoch 3/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - accuracy: 0.6614 - loss: 0.8366 - val_accuracy: 0.4932 - val_loss: 0.7912 - learning_rate: 1.0000e-04\n","Epoch 4/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6770 - loss: 0.7488"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 185ms/step - accuracy: 0.6771 - loss: 0.7485 - val_accuracy: 0.7217 - val_loss: 0.5517 - learning_rate: 1.0000e-04\n","Epoch 5/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.7003 - loss: 0.6985 - val_accuracy: 0.6448 - val_loss: 0.6329 - learning_rate: 1.0000e-04\n","Epoch 6/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7167 - loss: 0.6465"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 187ms/step - accuracy: 0.7165 - loss: 0.6471 - val_accuracy: 0.7896 - val_loss: 0.5313 - learning_rate: 1.0000e-04\n","Epoch 7/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 161ms/step - accuracy: 0.7283 - loss: 0.6276 - val_accuracy: 0.7805 - val_loss: 0.6223 - learning_rate: 1.0000e-04\n","Epoch 8/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - accuracy: 0.7165 - loss: 0.6003 - val_accuracy: 0.7104 - val_loss: 0.7109 - learning_rate: 1.0000e-04\n","Epoch 9/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7340 - loss: 0.5567"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 184ms/step - accuracy: 0.7339 - loss: 0.5568 - val_accuracy: 0.8213 - val_loss: 0.4572 - learning_rate: 1.0000e-04\n","Epoch 10/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.7200 - loss: 0.5785 - val_accuracy: 0.7941 - val_loss: 0.5103 - learning_rate: 1.0000e-04\n","Epoch 11/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - accuracy: 0.7192 - loss: 0.5639 - val_accuracy: 0.7919 - val_loss: 0.4799 - learning_rate: 1.0000e-04\n","Epoch 12/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 161ms/step - accuracy: 0.7338 - loss: 0.5452 - val_accuracy: 0.7760 - val_loss: 0.4911 - learning_rate: 1.0000e-04\n","Epoch 13/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 161ms/step - accuracy: 0.7509 - loss: 0.5157 - val_accuracy: 0.7760 - val_loss: 0.5461 - learning_rate: 5.0000e-05\n","Epoch 14/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7677 - loss: 0.4911 - val_accuracy: 0.8145 - val_loss: 0.5038 - learning_rate: 5.0000e-05\n","Epoch 15/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.7956 - loss: 0.4224 - val_accuracy: 0.8145 - val_loss: 0.4788 - learning_rate: 5.0000e-05\n","Epoch 1/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 203ms/step - accuracy: 0.7254 - loss: 0.5643 - val_accuracy: 0.7919 - val_loss: 0.4634 - learning_rate: 1.0000e-05\n","Epoch 2/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.7250 - loss: 0.5829 - val_accuracy: 0.7941 - val_loss: 0.4630 - learning_rate: 1.0000e-05\n","Epoch 3/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 161ms/step - accuracy: 0.7404 - loss: 0.5265 - val_accuracy: 0.7986 - val_loss: 0.4752 - learning_rate: 1.0000e-05\n","Epoch 4/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 162ms/step - accuracy: 0.7510 - loss: 0.5180 - val_accuracy: 0.8100 - val_loss: 0.4903 - learning_rate: 1.0000e-05\n","Epoch 5/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.7366 - loss: 0.5278 - val_accuracy: 0.7760 - val_loss: 0.5170 - learning_rate: 1.0000e-05\n","Epoch 6/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 163ms/step - accuracy: 0.7638 - loss: 0.4934 - val_accuracy: 0.7986 - val_loss: 0.4936 - learning_rate: 5.0000e-06\n","Epoch 7/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.7502 - loss: 0.5258 - val_accuracy: 0.7602 - val_loss: 0.5331 - learning_rate: 5.0000e-06\n","Epoch 8/10\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 165ms/step - accuracy: 0.7393 - loss: 0.5085 - val_accuracy: 0.7805 - val_loss: 0.5188 - learning_rate: 5.0000e-06\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["#Colab: 04_train_transfer.ipynb\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.metrics import Precision, Recall\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","import pickle\n","PROJECT_ROOT='/content/drive/MyDrive/aerial_project'\n","CLASSIFICATION_DIR=os.path.join(PROJECT_ROOT, 'classification_dataset')\n","DETECTION_DIR=os.path.join(PROJECT_ROOT, 'object_detection_Dataset')\n","DATA_DIR=os.path.join(PROJECT_ROOT, 'data')\n","SAVED_MODELS=os.path.join(PROJECT_ROOT, 'saved_models')\n","RESULTS_DIR=os.path.join(PROJECT_ROOT, 'results')\n","#create important folders if they don't exist\n","os.makedirs(SAVED_MODELS, exist_ok=True)\n","os.makedirs(RESULTS_DIR, exist_ok=True)\n","print('PROJECT_ROOT:', PROJECT_ROOT)\n","print('CLASSIFICATION_DIR exists:', os.path.exists(CLASSIFICATION_DIR))\n","print('DETECTION_DIR exists:', os.path.exists(DETECTION_DIR))\n","\n","#Data augmentation setup (copied from nb. 02)\n","data_augmentation=tf.keras.Sequential([\n","    layers.RandomFlip('horizontal'),\n","    layers.RandomRotation(0.12),\n","    layers.RandomZoom(0.12),\n","    layers.RandomTranslation(0.08, 0.08),\n","], name='data_augmentation')\n","\n","def build_efficientnet(input_shape=(224,224,3), num_classes=2, freeze_until=100):\n","  base=EfficientNetB0(include_top=False, input_shape=input_shape, weights='imagenet')\n","  base.trainable=True\n","  for layer in base.layers[:freeze_until]:\n","    layer.trainable=False\n","\n","  inputs=layers.Input(shape=input_shape)\n","  x=layers.Rescaling(1./255)(inputs)\n","  x=data_augmentation(x)\n","  x=base(x, training=False)\n","  x=layers.GlobalAveragePooling2D()(x)\n","  x=layers.BatchNormalization()(x)\n","  x=layers.Dropout(0.4)(x)\n","  x=layers.Dense(256, activation='relu')(x)\n","  x=layers.Dropout(0.3)(x)\n","  outputs=layers.Dense(num_classes, activation='softmax')(x)\n","  return models.Model(inputs, outputs, name='efficientnet_b0')\n","\n","model=build_efficientnet()\n","model.summary()\n","\n","model.compile(\n","optimizer=tf.keras.optimizers.Adam(1e-4),\n","loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","metrics=['accuracy'])\n","\n","callbacks=[\n","tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n","tf.keras.callbacks.ModelCheckpoint(os.path.join(SAVED_MODELS,'best_efficientnet.h5'), save_best_only=True, monitor='val_loss'),\n","tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)]\n","\n","#Dataset Loading and Class Weight Setup (copied from nb. 03)\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from sklearn.utils import class_weight\n","import numpy as np\n","\n","IMG_SIZE=(224, 224)\n","BATCH_SIZE=32\n","\n","#train, val, test datasets\n","train_ds=tf.keras.utils.image_dataset_from_directory(\n","    os.path.join(CLASSIFICATION_DIR, 'train'),\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE)\n","\n","val_ds=tf.keras.utils.image_dataset_from_directory(\n","    os.path.join(CLASSIFICATION_DIR, 'valid'),\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE)\n","\n","test_ds=tf.keras.utils.image_dataset_from_directory(\n","    os.path.join(CLASSIFICATION_DIR, 'test'),\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE)\n","\n","# class names\n","class_names=train_ds.class_names\n","print(\"Classes:\", class_names)\n","\n","# Compute class weights (to handle imbalance)\n","labels=np.concatenate([y for x, y in train_ds], axis=0)\n","class_weights_vals=class_weight.compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(labels),\n","    y=labels\n",")\n","class_weights=dict(enumerate(class_weights_vals))\n","print(\"Class Weights:\", class_weights)\n","\n","# Prefetch for performance\n","AUTOTUNE=tf.data.AUTOTUNE\n","train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","val_ds=val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","test_ds=test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","history=model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=callbacks, class_weight=class_weights)\n","\n","#optional fine-tuning: unfreezing the last N layers and train with lower lr\n","fine_tune_at=len(model.layers)-50\n","for layer in model.layers[fine_tune_at:]:\n","  layer.trainable=True\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n","loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","metrics=['accuracy'])\n","history_finetune=model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=callbacks, class_weight=class_weights)\n","\n","#saving history and model\n","import pickle\n","with open(os.path.join(SAVED_MODELS,'history_efficientnet.pkl'),'wb') as f:\n","  pickle.dump({'initial': history.history, 'finetune': history_finetune.history}, f)\n","model.save(os.path.join(SAVED_MODELS,'best_efficientnet_full.h5'))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50233,"status":"ok","timestamp":1761331459465,"user":{"displayName":"Anshav Desai","userId":"12679447231453701304"},"user_tz":-330},"id":"VIy8e_buUIRg","outputId":"87118f00-7c51-4068-ddd3-b12ff8c5c82c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 508ms/step\n","              precision    recall  f1-score   support\n","\n","        bird       0.88      0.69      0.77       121\n","       drone       0.69      0.87      0.77        94\n","\n","    accuracy                           0.77       215\n","   macro avg       0.78      0.78      0.77       215\n","weighted avg       0.79      0.77      0.77       215\n","\n","Confusion Matrix:\n"," [[84 37]\n"," [12 82]]\n"]}],"source":["#Manual evaluation metrics (after training)\n","from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","#Get predictions\n","y_true = np.concatenate([y for x, y in test_ds], axis=0)\n","y_pred_probs = model.predict(test_ds)\n","y_pred = np.argmax(y_pred_probs, axis=1)\n","#Classification report\n","print(classification_report(y_true, y_pred, target_names=class_names))\n","#Confusion matrix\n","cm=confusion_matrix(y_true, y_pred)\n","print(\"Confusion Matrix:\\n\", cm)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNbc4ibnF7irXZr+vR4vajR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}